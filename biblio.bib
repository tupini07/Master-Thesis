@article{dunn46_recor_linkag,
  author =       {Halbert L. Dunn},
  title =        {Record Linkage},
  journal =      {American Journal of Public Health and the Nations Health},
  volume =       36,
  number =       12,
  pages =        {1412-1416},
  year =         1946,
  doi =          {10.2105/ajph.36.12.1412},
  url =          {https://doi.org/10.2105/ajph.36.12.1412},
  DATE_ADDED =   {Fri Sep 20 14:06:15 2019},
}

@article{newcombe59_autom_linkag_vital_recor,
  author =       {H. B. Newcombe and J. M. Kennedy and S. J. Axford and A. P.
                  James},
  title =        {Automatic Linkage of Vital Records: Computers Can Be Used To
                  Extract "Follow-Up" Statistics of Families From Files of
                  Routine Records},
  journal =      {Science},
  volume =       130,
  number =       3381,
  pages =        {954-959},
  year =         1959,
  doi =          {10.1126/science.130.3381.954},
  url =          {https://doi.org/10.1126/science.130.3381.954},
  DATE_ADDED =   {Fri Sep 20 14:18:40 2019},
}

@article{fellegi69_theor_recor_linkag,
  author =       {Ivan P. Fellegi and Alan B. Sunter},
  title =        {A Theory for Record Linkage},
  journal =      {Journal of the American Statistical Association},
  volume =       64,
  number =       328,
  pages =        {1183-1210},
  year =         1969,
  doi =          {10.1080/01621459.1969.10501049},
  url =          {https://doi.org/10.1080/01621459.1969.10501049},
  DATE_ADDED =   {Fri Sep 20 14:28:21 2019},
}

@Book{christen12_data,
  author =       {Christen, Peter},
  title =        {Data matching : concepts and techniques for record linkage,
  entity resolution, and duplicate detection},
  year =         2012,
  publisher =    {Springer},
  address =      {Berlin New York},
  isbn =         9783642311635,
}

@article{christen12_survey_index_techn_scalab_recor_linkag_dedup,
  author =       {Peter Christen},
  title =        {A Survey of Indexing Techniques for Scalable Record Linkage
                  and Deduplication},
  journal =      {IEEE Transactions on Knowledge and Data Engineering},
  volume =       24,
  number =       9,
  pages =        {1537-1555},
  year =         2012,
  doi =          {10.1109/tkde.2011.127},
  url =          {https://doi.org/10.1109/tkde.2011.127},
  DATE_ADDED =   {Fri Sep 27 13:53:54 2019},
}

@inproceedings{winkler2006overview,
  title={Overview of record linkage and current research directions},
  author={Winkler, William E},
  booktitle={Bureau of the Census},
  year={2006},
  organization={Citeseer},
  DATE_ADDED =   {Fri Sep 27 13:53:54 2019},
}

@inproceedings{Baxter2003ACO,
  title={A Comparison of Fast Blocking Methods for Record Linkage},
  author={Rohan A. Baxter and Peter Christen and Tim Churches},
  booktitle={KDD 2003},
  year={2003}
}

@article{Sayers2015,
  doi = {10.1093/ije/dyv322},
  url = {https://doi.org/10.1093/ije/dyv322},
  year = {2015},
  month = dec,
  publisher = {Oxford University Press ({OUP})},
  volume = {45},
  number = {3},
  pages = {954--964},
  author = {Adrian Sayers and Yoav Ben-Shlomo and Ashley W Blom and Fiona Steele},
  title = {Probabilistic record linkage},
  journal = {International Journal of Epidemiology}
}

@article{@clark2004_rl_for_injury,
 author = {Clark, D E},
 title = {Practical introduction to record linkage for injury research.},
 abstract = {The frequency of early fatality and the transient nature of emergency medical
      care mean that a single database will rarely suffice for population based injury 
      research. Linking records from multiple data sources is therefore a promising
      method for injury surveillance or trauma system evaluation. The purpose of this
      article is to review the historical development of record linkage, provide a
      basic mathematical foundation, discuss some practical issues, and consider some
      ethical concerns. Clerical or computer assisted deterministic record linkage
      methods may suffice for some applications, but probabilistic methods are
      particularly useful for larger studies. The probabilistic method attempts to
      simulate human reasoning by comparing each of several elements from the two
      records. The basic mathematical specifications are derived algebraically from
      fundamental concepts of probability, although the theory can be extended to
      include more advanced mathematics. Probabilistic, deterministic, and clerical
      techniques may be combined in different ways depending upon the goal of the
      record linkage project. If a population parameter is being estimated for a purely
      statistical study, a completely probabilistic approach may be most efficient; for
      other applications, where the purpose is to make inferences about specific
      individuals based upon their data contained in two or more files, the need for a 
      high positive predictive value would favor a deterministic method or a
      probabilistic method with careful clerical review. Whatever techniques are used, 
      researchers must realize that the combination of data sources entails additional 
      ethical obligations beyond the use of each source alone.},
 journal = {Injury prevention : journal of the International Society for Child and Adolescent
      Injury Prevention},
 volume = {10},
 number = {3},
 year = {2004},
 pages = {186-91},
 doi = {10.1136/ip.2003.004580},
}

@article{Churches2002,
  author =       {Tim Churches and Peter Christen and Kim Lim and Justin Xi Zhu},
  title =        {Preparation of name and address data for record linkage using
                  hidden Markov models},
  journal =      {{BMC} Medical Informatics and Decision Making},
  volume =       2,
  number =       1,
  year =         2002,
  doi =          {10.1186/1472-6947-2-9},
  url =          {https://doi.org/10.1186/1472-6947-2-9},
  month =        dec,
  publisher =    {Springer Nature},
}


@article{Rahm00datacleaning,
  author =       {Erhard Rahm and Hong Hai Do},
  title =        {Data Cleaning: Problems and Current Approaches},
  journal =      {IEEE Data Engineering Bulletin},
  volume =       23,
  pages =        2000,
  year =         2000,
}


@inbook{gu06_decis_model_recor_linkag,
  DATE_ADDED =   {Sat Sep 28 13:10:08 2019},
  author =       {Lifang Gu and Rohan Baxter},
  booktitle =    {Lecture Notes in Computer Science},
  doi =          {10.1007/11677437_12},
  pages =        {146-160},
  publisher =    {Springer Berlin Heidelberg},
  series =       {Lecture Notes in Computer Science},
  title =        {Decision Models for Record Linkage},
  url =          {https://doi.org/10.1007/11677437_12},
  year =         {2006},
}

@inproceedings{Elfeky,
  doi = {10.1109/icde.2002.994694},
  url = {https://doi.org/10.1109/icde.2002.994694},
  publisher = {{IEEE} Comput. Soc},
  author = {M.G. Elfeky and V.S. Verykios and A.K. Elmagarmid},
  title = {{TAILOR}: a record linkage toolbox},
  booktitle = {Proceedings 18th International Conference on Data Engineering},
  year = {2002},
}

@article{Hartigan1979,
  doi = {10.2307/2346830},
  url = {https://doi.org/10.2307/2346830},
  year = {1979},
  publisher = {{JSTOR}},
  volume = {28},
  number = {1},
  pages = {100},
  author = {J. A. Hartigan and M. A. Wong},
  title = {Algorithm {AS} 136: A K-Means Clustering Algorithm},
  journal = {Applied Statistics}
}



@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I},
  booktitle={Soviet physics doklady},
  volume={10},
  pages={707--710},
  year={1966}
}

@article{Kalashnikov2006_collective_graph,
  author =       {Kalashnikov, Dmitri V. and Mehrotra, Sharad},
  title =        {Domain-independent Data Cleaning via Analysis of
                  Entity-relationship Graph},
  journal =      {ACM Trans. Database Syst.},
  volume =       31,
  number =       2,
  pages =        {716--767},
  year =         2006,
  doi =          {10.1145/1138394.1138401},
  url =          {http://doi.acm.org/10.1145/1138394.1138401},
  acmid =        1138401,
  address =      {New York, NY, USA},
  issn =         {0362-5915},
  issue_date =   {June 2006},
  keywords =     {Connection strength, RelDC, data cleaning, entity resolution,
                  graph analysis, reference disambiguation, relationship
                  analysis},
  month =        jun,
  numpages =     52,
  publisher =    {ACM},
}


@inproceedings{Dong2005_reference_reconciliation,
  author =       {Dong, Xin and Halevy, Alon and Madhavan, Jayant},
  title =        {Reference Reconciliation in Complex Information Spaces},
  booktitle =    {Proceedings of the 2005 ACM SIGMOD International Conference on
                  Management of Data},
  year =         2005,
  pages =        {85--96},
  doi =          {10.1145/1066157.1066168},
  url =          {http://doi.acm.org/10.1145/1066157.1066168},
  acmid =        1066168,
  address =      {New York, NY, USA},
  isbn =         {1-59593-060-4},
  location =     {Baltimore, Maryland},
  numpages =     12,
  publisher =    {ACM},
  series =       {SIGMOD '05},
}


@article{bhattacharya07_collec_entit_resol_relat_data,
  author =       {Indrajit Bhattacharya and Lise Getoor},
  title =        {Collective Entity Resolution in Relational Data},
  journal =      {ACM Transactions on Knowledge Discovery from Data},
  volume =       1,
  number =       1,
  pages =        {5-es},
  year =         2007,
  doi =          {10.1145/1217299.1217304},
  url =          {https://doi.org/10.1145/1217299.1217304},
  DATE_ADDED =   {Sun Sep 29 11:54:31 2019},
}

@article{Powers2011_evaluation,
  author =       {Powers, David and Ailab,},
  title =        {Evaluation: From precision, recall and F-measure to ROC,
                  informedness, markedness \& correlation},
  journal =      {J. Mach. Learn. Technol},
  volume =       2,
  pages =        {2229-3981},
  year =         2011,
  doi =          {10.9735/2229-3981},
  month =        01,
}


@article{hand17_note_using_f_measur_evaluat,
  author =       {David Hand and Peter Christen},
  title =        {A Note on Using the F-Measure for Evaluating Record Linkage
                  Algorithms},
  journal =      {Statistics and Computing},
  volume =       28,
  number =       3,
  pages =        {539-547},
  year =         2017,
  doi =          {10.1007/s11222-017-9746-6},
  url =          {https://doi.org/10.1007/s11222-017-9746-6},
  DATE_ADDED =   {Sun Sep 29 12:36:42 2019},
}

@InProceedings{mckinney-proc-scipy-2010,
  author =       { Wes McKinney },
  title =        { Data Structures for Statistical Computing in Python },
  booktitle =    { Proceedings of the 9th Python in Science Conference },
  year =         { 2010 },
  pages =        { 51 - 56 },
  editor =       { St\'efan van der Walt and Jarrod Millman },
}


@article{scikit-learn,
  author =       {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel,
                  V. and Thirion, B. and Grisel, O. and Blondel, M. and
                  Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas,
                  J. and Passos, A. and Cournapeau, D. and Brucher, M. and
                  Perrot, M. and Duchesnay, E.},
  title =        {Scikit-learn: Machine Learning in {P}ython},
  journal =      {Journal of Machine Learning Research},
  volume =       12,
  pages =        {2825--2830},
  year =         2011,
}

@misc{recordlinkage-library,
  author = {Jonathan de Bruin},
  title = {{recordlinkage (version 0.13.2)}},
  year  = {2019},
howpublished={\url{https://recordlinkage.readthedocs.io/en/latest/about.html}},
  note = "[Online; accessed 27-September-2019]",
}

@incollection{sqlalchemy,
  author =       {Bayer, Michael},
  booktitle =    {The Architecture of Open Source Applications Volume II:
                  Structure, Scale, and a Few More Fearless Hacks},
  editor =       {Brown, Amy and Wilson, Greg},
  place =        {Mountain View},
  publisher =    {aosabook.org},
  title =        {SQLAlchemy},
  url =          "http://aosabook.org/en/sqlalchemy.html",
  year =         2012,
}


@misc{flennerhag:2017mlens,
  author =       {Flennerhag, Sebastian},
  doi =          {10.5281/zenodo.1042144},
  month =        nov,
  title =        {ML-Ensemble},
  url =          {https://dx.doi.org/10.5281/zenodo.1042144},
  year =         2017,
}


@Techreport{python-tutorial,
  address =      {Amsterdam},
  author =       {G. van Rossum},
  institution =  {Centrum voor Wiskunde en Informatica (CWI)},
  month =        {May},
  number =       {CS-R9526},
  title =        {Python tutorial},
  year =         1995,
}


@Article{Hunter_Matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}


@misc{Seaborn,
  doi = {10.5281/ZENODO.12710},
  url = {https://zenodo.org/record/12710},
  author = {Waskom,  Michael and Botvinnik,  Olga and Hobson,  Paul and Cole,  John B. and Halchenko,  Yaroslav and Hoyer,  Stephan and Miles,  Alistair and Augspurger,  Tom and Yarkoni,  Tal and Megies,  Tobias and Coelho,  Luis Pedro and Wehner,  Daniel and {Cynddl} and Ziegler,  Erik and {Diego0020} and Zaytsev,  Yury V. and Hoppe,  Travis and {Skipper Seabold} and Cloud,  Phillip and Koskinen,  Miikka and Meyer,  Kyle and Qalieh,  Adel and Allan,  Dan},
  title = {Seaborn: V0.5.0 (November 2014)},
  publisher = {Zenodo},
  year = {2014}
}


@article{singhal_modern_information_retrieval,
title	= {Modern Information Retrieval: A Brief Overview},
author	= {Amit Singhal},
year	= {2001},
journal	= {IEEE Data Eng. Bull.},
pages	= {35-43},
volume	= {24}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
}


@incollection{Munro2011_bias_variance_decomp,
  doi = {10.1007/978-0-387-30164-8_74},
  url = {https://doi.org/10.1007/978-0-387-30164-8_74},
  year = {2011},
  publisher = {Springer {US}},
  pages = {100--101},
  author = {Paul Munro and Hannu Toivonen and Geoffrey I. Webb and Wray Buntine and Peter Orbanz and Yee Whye Teh and Pascal Poupart and Claude Sammut and Caude Sammut and Hendrik Blockeel and Dev Rajnarayan and David Wolpert and Wulfram Gerstner and C. David Page and Sriraam Natarajan and Geoffrey Hinton},
  title = {Bias Variance Decomposition},
  booktitle = {Encyclopedia of Machine Learning}
}


@Article{Breiman1996_bagging_predictors,
author="Breiman, Leo",
title="Bagging predictors",
journal="Machine Learning",
year="1996",
month="Aug",
day="01",
volume="24",
number="2",
pages="123--140",
abstract="Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy.",
issn="1573-0565",
doi="10.1007/BF00058655",
url="https://doi.org/10.1007/BF00058655"
}


@inproceedings{Kohavi:1995_study_of_cross_validation,
 author = {Kohavi, Ron},
 title = {A Study of Cross-validation and Bootstrap for Accuracy Estimation and Model Selection},
 booktitle = {Proceedings of the 14th International Joint Conference on Artificial Intelligence - Volume 2},
 series = {IJCAI'95},
 year = {1995},
 isbn = {1-55860-363-8},
 location = {Montreal, Quebec, Canada},
 pages = {1137--1143},
 numpages = {7},
 url = {http://dl.acm.org/citation.cfm?id=1643031.1643047},
 acmid = {1643047},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{clauset2011brief,
  title={A brief primer on probability distributions},
  author={Clauset, Aaron},
  booktitle={Santa Fe Institute},
  year={2011}
}

@article{Cawley:2010_crossval_model_selection,
 author = {Cawley, Gavin C. and Talbot, Nicola L.C.},
 title = {On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation},
 journal = {J. Mach. Learn. Res.},
 issue_date = {3/1/2010},
 volume = {11},
 month = aug,
 year = {2010},
 issn = {1532-4435},
 pages = {2079--2107},
 numpages = {29},
 url = {http://dl.acm.org/citation.cfm?id=1756006.1859921},
 acmid = {1859921},
 publisher = {JMLR.org},
} 

